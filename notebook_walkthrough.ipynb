{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33730e0-0b57-4dab-b2ec-a82beb2628df",
   "metadata": {},
   "source": [
    "## Run and Evaluate DeepSeek-R1 (distilled model) with Ollama and OpenAI's simple-evals\n",
    "### Notebook Walkthrough\n",
    "Author: Kenneth Leung\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21906c-b8e8-4d70-8d84-e18ff04aa628",
   "metadata": {},
   "source": [
    "### (1) Installation Instructions\n",
    "- Download and install Ollama from https://ollama.com/download\n",
    "- To start Ollama, either open the Ollama app on your local machine, or run `ollama serve` in the terminal.\n",
    "- We will be working with the distilled DeepSeek-R1-Distill-Qwen-7B model. Pull the model by running the following command in terminal:\n",
    "  - `ollama pull deepseek-r1:7b`\n",
    "- Once done, we return to this notebook to continue with the Python codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c95fe-f8af-43c6-8ade-e501bf6fca93",
   "metadata": {},
   "source": [
    "### (2) Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6131a4-115c-4a07-bff7-9d83ae6b4a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_evals'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msimple_evals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgpqa_eval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPQAEval\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msamplers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mollama_sampler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaSampler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'simple_evals'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "from simple_evals.gpqa_eval import GPQAEval\n",
    "\n",
    "from utils.utils import load_config\n",
    "from samplers.ollama_sampler import OllamaSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5abb89b-a0e2-4156-856b-a1527746fbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL_NAME': 'deepseek-r1:7b'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config(\"src/config/config.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db30f7cd-cb61-4ce6-95bf-53df7ec4c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListResponse(models=[Model(model='deepseek-r1:1.5b', modified_at=datetime.datetime(2025, 3, 6, 11, 33, 42, 130232, tzinfo=TzInfo(+08:00)), digest='a42b25d8c10a841bd24724309898ae851466696a7d7f3a0a408b895538ccbc96', size=1117322599, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='1.8B', quantization_level='Q4_K_M')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 6, 11, 20, 52, 985187, tzinfo=TzInfo(+08:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that our model has been downloaded\n",
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cf65cb-74b1-4483-be37-fcf98b33fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"What is the capital of China?\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an advanced AI assistant analyzing an alien civilizationâ€™s mathematical system. \n",
    "They use an unfamiliar number system, and their number patterns follow unknown rules. \n",
    "You receive the following number sequences and must determine the missing number:\n",
    "\n",
    "Sequences:\n",
    "3, 6, 11, 18, 27, ?\n",
    "2, 6, 12, 20, 30, ?\n",
    "5, 10, 18, 30, 47, ?\n",
    "Rules:\n",
    "The aliens do not use base-10 but instead follow their own logical sequence.\n",
    "Each sequence follows a hidden pattern based on an unknown mathematical principle.\n",
    "You must determine the next number in each sequence and briefly explain the reasoning behind it.\n",
    "\n",
    "Ensure you initiate your response with \"<think>\\n at the beginning of your output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e99753-d77e-44d3-b65e-482ac44063c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Time: 2 min 8.55 sec\n",
      "\n",
      "<think>\n",
      "Okay, so I need to figure out what the capital of China is. Hmm, I remember learning about capitals in school when we studied countries and their capitals. Let me think... I'm pretty sure it's a city that's both the political center and where the president lives.\n",
      "\n",
      "I know that other countries like the United States have Washington D.C. as their capital, which isn't on the east coast but kind of mid-northwest in the U.S.A. Then there's Canada with Ottawa, which is right across the border from where I live in the southern part of Ontario. So maybe China has a similar situation?\n",
      "\n",
      "Wait, I'm pretty sure that besides Beijing, there's also Shanghai and Shenzhen. I think Shanghai is the economic capital because it's big and has all those financial activities, while Shenzhen is more modern and tech-oriented. But which one is considered the political or official capital? I believe it's Beijing where all the government stuff happens, like the President lives there.\n",
      "\n",
      "Let me try to recall any specific details about Beijing. It's been a major city for a long time; I remember learning that it was the first capital of China in the 19th century when they were modernizing and wanting to establish a strong central government. Since then, it's grown into one of the largest cities in the world with all its infrastructure.\n",
      "\n",
      "Also, I think I've heard about the Great Wall being located near Beijing. That must have been a strategic choice for the Chinese Communist Party to ensure control over such a long border. So, putting that together, Beijing seems like the logical choice as both the political and administrative capital of China.\n",
      "</think>\n",
      "\n",
      "The capital of China is Beijing.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response: ollama.ChatResponse = ollama.chat(model=config[\"MODEL_NAME\"], \n",
    "                                            messages=[\n",
    "                                              {'role': 'user',\n",
    "                                               'content': prompt},\n",
    "                                            ])\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "minutes = int(execution_time // 60)\n",
    "seconds = execution_time % 60\n",
    "if minutes > 0:\n",
    "    print(f\"\\nExecution Time: {minutes} min {seconds:.2f} sec\\n\")\n",
    "else:\n",
    "    print(f\"\\nExecution Time: {seconds:.2f} sec\\n\")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3bd6b-18fb-4823-87d2-2b1dd3ae4ea3",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7f305-39fb-4821-9b1b-7305da41d2e7",
   "metadata": {},
   "source": [
    "## Initiate GPQA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6532ce-7f60-47fe-9985-62d06eab8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ollama wrapper that wraps ollama.chat() to format prompts correctly and retrieve responses for GPQA eval\n",
    "ollama_sampler = OllamaSampler(model_name=config[\"MODEL_NAME\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a0e7577-ad88-4ee1-9200-8623941550e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = GPQAEval(n_repeats=1, num_examples=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc66144-4159-450d-9a9f-952045f40f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "result = evaluator(ollama_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532dfe8-44c5-4d62-8dc7-c6e0ec008909",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_deepseek_ollama",
   "language": "python",
   "name": "venv_deepseek_ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
